{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.34-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.3.0)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.3.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.0)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.18.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\su20340119\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\su20340119\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\su20340119\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\su20340119\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\su20340119\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\su20340119\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.34-py3-none-any.whl (887 kB)\n",
      "   ---------------------------------------- 0.0/887.4 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/887.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 266.2/887.4 kB 2.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 460.8/887.4 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/887.4 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 887.4/887.4 kB 3.7 MB/s eta 0:00:00\n",
      "Using cached lxml-5.3.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, opencv-python, lxml, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed lxml-5.3.0 opencv-python-4.10.0.84 py-cpuinfo-9.0.0 seaborn-0.13.2 ultralytics-8.3.34 ultralytics-thop-2.0.12\n"
     ]
    }
   ],
   "source": [
    "# pip install ultralytics pillow lxml scikit-learn\n",
    "\n",
    "# Import library\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names and their corresponding IDs\n",
    "class_names = {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\n",
    "annotations_dir = 'datasets/annotations'\n",
    "images_dir = 'datasets/images'\n",
    "output_dir = 'datasets/dataset'\n",
    "os.makedirs(f\"{output_dir}/images\", exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/labels\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "images_dir = 'datasets/images'\n",
    "annotations_dir = 'datasets/annotations'\n",
    "\n",
    "train_images_dir = 'datasets/train/images'\n",
    "train_annotations_dir = 'datasets/train/annotations'\n",
    "val_images_dir = 'datasets/val/images'\n",
    "val_annotations_dir = 'datasets/val/annotations'\n",
    "test_images_dir = 'datasets/test/images'\n",
    "test_annotations_dir = 'datasets/test/annotations'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_annotations_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_annotations_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_annotations_dir, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "\n",
    "# Split the dataset into train and temp (which will be further split into val and test)\n",
    "train_files, temp_files = train_test_split(image_files, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temp dataset into val and test\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Copy files to train directories\n",
    "for file in train_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(train_images_dir, file))\n",
    "    shutil.copy(os.path.join(annotations_dir, file.replace('.png', '.xml')), os.path.join(train_annotations_dir, file.replace('.png', '.xml')))\n",
    "\n",
    "# Copy files to val directories\n",
    "for file in val_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(val_images_dir, file))\n",
    "    shutil.copy(os.path.join(annotations_dir, file.replace('.png', '.xml')), os.path.join(val_annotations_dir, file.replace('.png', '.xml')))\n",
    "\n",
    "# Copy files to test directories\n",
    "for file in test_files:\n",
    "    shutil.copy(os.path.join(images_dir, file), os.path.join(test_images_dir, file))\n",
    "    shutil.copy(os.path.join(annotations_dir, file.replace('.png', '.xml')), os.path.join(test_annotations_dir, file.replace('.png', '.xml')))\n",
    "\n",
    "print(\"Dataset split into training, validation, and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_text = \"\"\"\n",
    "train: datasets/train/images\n",
    "test: datasets/test/images\n",
    "val: datasets/train/images\n",
    "nc: 3  # number of classes (with_mask, without_mask, mask_weared_incorrect)\n",
    "names: ['with_mask', 'without_mask', 'mask_weared_incorrect']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", 'w') as file:\n",
    "    file.write(yaml_text)\n",
    "\n",
    "with open(\"data.yaml\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert annotation to labels for yolo\n",
    "def convert_xml_to_yolo(xml_file, output_dir, dtatype):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    image_id = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "    yolo_annotation = []\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        if class_name not in class_names:\n",
    "            print(f\"Warning: Class '{class_name}' not found in class_names. Skipping.\")\n",
    "            continue\n",
    "        class_id = class_names[class_name]\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        \n",
    "        x_center = (xmin + xmax) / 2.0\n",
    "        y_center = (ymin + ymax) / 2.0\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        \n",
    "        # Load the image to get its dimensions\n",
    "        img_path = os.path.join('datasets/' + dtatype + '/images', f\"{image_id}.png\")\n",
    "        with Image.open(img_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "        \n",
    "        x_center /= img_width\n",
    "        y_center /= img_height\n",
    "        width /= img_width\n",
    "        height /= img_height\n",
    "        \n",
    "        yolo_annotation.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    with open(os.path.join(output_dir, f\"{image_id}.txt\"), 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_annotation))\n",
    "\n",
    "# Convert all XML files in the annotations directory\n",
    "data_list = ['train', 'test', 'val']\n",
    "for i in data_list:\n",
    "    annotations_dir = 'datasets/' + i + '/annotations'\n",
    "    output_dir = 'datasets/' + i + '/labels'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Train conversion\n",
    "    for xml_file in os.listdir(annotations_dir):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            convert_xml_to_yolo(os.path.join(annotations_dir, xml_file), output_dir, i)\n",
    "\n",
    "print(\"Conversion completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # You can choose different versions like yolov8s.pt, yolov8m.pt, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "model.train(data='data.yaml', epochs=1, imgsz=640, lr0=0.001)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('trained_weights/yolov8n_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of trained model weights\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO('trained_weights/yolov8n_trained.pt')  # Make sure the path to your trained model file is correct\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = model.val(data='data.yaml', split='test')  # Specify the test split\n",
    "print(results)\n",
    "# Print the evaluation results\n",
    "print(f\"mAP: {results.box.map}\")\n",
    "print(f\"mAP@50: {results.box.map50}\")\n",
    "print(f\"mAP@75: {results.box.map75}\")\n",
    "print(f\"Precision: {results.box.mp}\")\n",
    "print(f\"Recall: {results.box.mr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLOv8 model\n",
    "model = YOLO('trained_weights/yolov8n_trained.pt')  # Make sure the path to your trained model file is correct\n",
    "\n",
    "# Get predictions from the model on the test data\n",
    "results = model.predict(source='datasets/test/images', save=False)  # Specify the test images folder\n",
    "\n",
    "# Define paths to the image and label folders\n",
    "image_folder = 'datasets/test/images'  # Replace with the actual path to your test images folder\n",
    "label_folder = 'datasets/test/labels'  # Replace with the actual path to your test labels folder\n",
    "\n",
    "# Get image names from the folder\n",
    "image_names = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "# Initialize lists to store ground truth labels and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Map labels from the folder and extract the first value before space as label\n",
    "for image_name in image_names:\n",
    "    label_file = os.path.join(label_folder, os.path.splitext(image_name)[0] + '.txt')\n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as f:\n",
    "            label = f.read().strip().split()[0]  # Extract the first value before space as label\n",
    "            y_true.append(int(label))  # Convert label to integer\n",
    "    else:\n",
    "        y_true.append(0)  # Default value if label file does not exist\n",
    "\n",
    "for result in results:\n",
    "    if result.boxes is not None:\n",
    "        for pred in result.boxes.cls:  # Assuming result.boxes.cls gives the predicted classes\n",
    "            y_pred.append(int(pred.item()))  # Convert tensor to integer\n",
    "    else:\n",
    "        y_pred.append(0)  # Default value if no prediction is made\n",
    "\n",
    "# Ensure y_pred has the same length as y_true by padding with default values if necessary\n",
    "while len(y_pred) < len(y_true):\n",
    "    y_pred.append(0)\n",
    "\n",
    "# Create a DataFrame with image names, actual labels, and predicted labels\n",
    "output_df = pd.DataFrame({\n",
    "    'Image Name': image_names,\n",
    "    'Actual Label': y_true,\n",
    "    'Predicted Label': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('output/custom_data_training.csv', index=False)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn heatmap with correct axis labels and title\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion  for face mask detection')\n",
    "plt.savefig('output/confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Output file and confusion matrix png saved successfully.\")\n",
    "\n",
    "\n",
    "# Export the trained model to ONNX format\n",
    "model.export(format='onnx')\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO('trained_weights/yolov8n_trained.onnx')  # Make sure the path to your model file is correct\n",
    "\n",
    "# Function to perform inference on an image and save the predicted image\n",
    "def perform_inference(image_path, save_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model.predict(img)\n",
    "    \n",
    "    # Save the predicted image\n",
    "    results[0].save(save_path)  # Access the first result and save the image with bounding boxes\n",
    "\n",
    "    # Optionally, you can print the results\n",
    "    predictions = results[0].boxes  # Access the bounding boxes\n",
    "    print(predictions)\n",
    "Image.open(\"output\\confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = 'datasets\\predict\\maksssksksss0.png'  # Replace with the path to your image\n",
    "save_path = 'output\\predicted\\maksssksksss0.jpg'  # Replace with the path where you want to save the predicted image\n",
    "perform_inference(image_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the trained model to ONNX format\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLOv8 model\n",
    "model = YOLO('trained_weights/yolov8n_trained.onnx')  # Make sure the path to your model file is correct\n",
    "\n",
    "# Function to perform inference on an image and save the predicted image\n",
    "def perform_inference(image_path, save_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model.predict(img)\n",
    "    \n",
    "    # Save the predicted image\n",
    "    results[0].save(save_path)  # Access the first result and save the image with bounding boxes\n",
    "\n",
    "    # Optionally, you can print the results\n",
    "    predictions = results[0].boxes  # Access the bounding boxes\n",
    "    print(predictions)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'datasets\\predict\\maksssksksss0.png'  # Replace with the path to your image\n",
    "save_path = 'output\\predicted\\maksssksksss0.jpg'  # Replace with the path where you want to save the predicted image\n",
    "perform_inference(image_path, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
